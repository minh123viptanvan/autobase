all:
  hosts:
    192.168.10.11:
      ansible_host: 192.168.10.11
      ansible_user: vagrant
      ansible_password: vagrant
      ansible_become_password: vagrant
      hostname: node1
    
    192.168.10.12:
      ansible_host: 192.168.10.12
      ansible_user: vagrant
      ansible_password: vagrant
      ansible_become_password: vagrant
      hostname: node2

    192.168.10.13:
      ansible_host: 192.168.10.13
      ansible_user: vagrant
      ansible_password: vagrant
      ansible_become_password: vagrant
      hostname: node3

  # vars:
    # ansible_ssh_common_args: -o "StrictHostKeyChecking no" -o ProxyCommand="ssh -W %h:%p -q 172.24.178.200"
    # proxy_env:
    #   http_proxy: http://proxy.hcm.fpt.vn:80
    #   https_proxy: http://proxy.hcm.fpt.vn:80
    #   no_proxy: mirror.cads.live

etcd_cluster:
  hosts:
    192.168.10.11:
    192.168.10.12:
    192.168.10.13:

postgres_cluster:
  children:
    master:
      hosts:
        192.168.10.11:
          is_master: true
          postgresql_exists: false
    replica:
      hosts:
        192.168.10.12:
          is_master: false
          postgresql_exists: false


balancers:
  hosts:
    192.168.10.11:
    192.168.10.12:

# pgbackrest:
#   hosts:
#     192.168.10.13:

etcd_cluster_postgres_cluster_balancer_pgbackrest:
  children:
    etcd_cluster:
    postgres_cluster:
    pgbackrest:
    balancers:
  vars:
    # You can also use your own repository for extra packages. You need to preload all the packages and change this URLs.
    installation_method: "repo"
    # DCS (Distributed Consensus Store)
    dcs_exists: false  # or 'true' if you don't want to deploy a new etcd cluster
    dcs_type: "etcd"  # or 'consul'

    # if dcs_type: "etcd" and dcs_exists: false
    etcd_version: "3.5.18"  # version for deploy etcd cluster
    etcd_data_dir: "/var/lib/etcd"
    etcd_cluster_name: "etcd-{{ patroni_cluster_name | default('postgres-cluster', true) }}"  # ETCD_INITIAL_CLUSTER_TOKEN
    # Extra packages
    etcd_package_repo: "https://github.com/etcd-io/etcd/releases/download/v{{ etcd_version }}/etcd-v{{ etcd_version }}-linux-amd64.tar.gz"

    patroni_installation_method: "pip"
    # (if patroni_installation_type: "pip")
    # Packages from your repository will be used to install instead of the pip repository.
    pip_package_repo: "https://bootstrap.pypa.io/get-pip.py"  # latest version pip3 for python3 (or use "pip-<version>.tar.gz").
    patroni_pip_requirements_repo: []
    patroni_pip_package_repo: []
    python_version: "3.12" # python3.9
    os_specific_packages:
      RedHat-7:
        - python
        - python-devel
        - python-psycopg2
        - python-setuptools
        - libselinux-python
        - libsemanage-python
        - policycoreutils-python
        - yum-utils
      RedHat-8:
        - python2
        - python3-libselinux
        - python3-libsemanage
        - python3-policycoreutils
        - dnf-utils
      RedHat-9:
        - python3-libselinux
        - python3-libsemanage
        - python3-policycoreutils
        - dnf-utils
    system_packages:
      - "{{ os_specific_packages[ 'RedHat' ~ '-' ~ ansible_distribution_major_version ] }}"
      - python{{ python_version }}
      - python{{ python_version }}-devel
      - python{{ python_version }}-psycopg2
      - python{{ python_version }}-setuptools
      - python{{ python_version }}-pip
      - python{{ python_version }}-urllib3
      - less
      - sudo
      - vim
      - gcc
      - jq
      - iptables
      - acl
      - bind-utils

    patroni_cluster_name: "pg-cluster-pgbench"  # the cluster name (must be unique for each cluster)
    patroni_install_version: "4.0.4"  # or 'latest'
    patroni_superuser_username: "postgres"
    patroni_superuser_password: "postgres-pass"  # please change password
    patroni_replication_username: "replicator"
    patroni_replication_password: "replicator-pass"  # please change password
    synchronous_mode: false  # or 'true' for enable synchronous database replication
    synchronous_mode_strict: false  # if 'true' then block all client writes to the master, when a synchronous replica is not available
    synchronous_node_count: 0  # number of synchronous standby databases
    # if dcs_type: "etcd" and dcs_exists: true
    patroni_etcd_hosts:  # list of servers of an existing etcd cluster
      - { host: "172.24.177.83", port: "2379" }
      # - { host: "10.128.64.142", port: "2379" }
      # - { host: "10.128.64.143", port: "2379" }
    patroni_etcd_namespace: "service"  # (optional) etcd namespace (prefix)
    # patroni_etcd_username: "{{ patroni_cluster_name }}" # (optional) username for etcd authentication
    # patroni_etcd_password: "{{ patroni_cluster_name }}" # (optional) password for etcd authentication
    patroni_etcd_protocol: "" # (optional) http or https, if not specified http is used
    # Extended variables (optional)
    patroni_restapi_listen_addr: "0.0.0.0" # Listen on all interfaces. Or use "{{ inventory_hostname }}" to listen on a specific IP address.
    patroni_restapi_port: 8008
    patroni_restapi_username: "patroni"
    patroni_restapi_password: "patroni-pass"  # please change password
    patroni_ttl: 30
    patroni_loop_wait: 10
    patroni_retry_timeout: 10
    patroni_master_start_timeout: 300
    patroni_maximum_lag_on_failover: 1048576 # (1MB) the maximum bytes a follower may lag to be able to participate in leader election.
    patroni_maximum_lag_on_replica: "10MB" # the maximum of lag that replica can be in order to be available for read-only queries.
    # https://patroni.readthedocs.io/en/latest/yaml_configuration.html#postgresql
    patroni_callbacks: []
    #  - {action: "on_role_change", script: ""}
    #  - {action: "on_stop", script: ""}
    #  - {action: "on_restart", script: ""}
    #  - {action: "on_reload", script: ""}
    #  - {action: "on_role_change", script: ""}
    # https://patroni.readthedocs.io/en/latest/replica_bootstrap.html#standby-cluster
    # Requirements:
    # 1. the cluster name for Standby Cluster must be unique ('patroni_cluster_name' variable)
    # 2. the IP addresses (or network) of the Standby Cluster servers must be added to the pg_hba.conf of the Main Cluster ('postgresql_pg_hba' variable).
    patroni_standby_cluster:
      host: ""  # an address of remote master
      port: "5432"  # a port of remote master
    #  primary_slot_name: ""  # which slot on the remote master to use for replication (optional)
    #  restore_command: ""  # command to restore WAL records from the remote master to standby leader (optional)
    #  recovery_min_apply_delay: ""  # how long to wait before actually apply WAL records on a standby leader (optional)
    # Permanent replication slots.
    # These slots will be preserved during switchover/failover.
    # https://patroni.readthedocs.io/en/latest/dynamic_configuration.html
    patroni_slots: []
    #  - slot: "logical_replication_slot" # the name of the permanent replication slot.
    #    type: "logical" # the type of slot. Could be 'physical' or 'logical' (if the slot is logical, you have to define 'database' and 'plugin').
    #    plugin: "pgoutput" # the plugin name for the logical slot.
    #    database: "postgres" # the database name where logical slots should be created.
    #  - slot: "test_logical_replication_slot"
    #    type: "logical"
    #    plugin: "pgoutput"
    #    database: "test"
    patroni_log_destination: logfile  # or 'logfile'
    # if patroni_log_destination: logfile
    patroni_log_dir: /var/log/patroni
    patroni_log_level: info
    patroni_log_traceback_level: error
    patroni_log_format: "%(asctime)s %(levelname)s: %(message)s"
    patroni_log_dateformat: ""
    patroni_log_max_queue_size: 1000
    patroni_log_file_num: 7
    patroni_log_file_size: 25000000  # bytes
    patroni_log_loggers_patroni_postmaster: warning
    patroni_log_loggers_urllib3: warning  # or 'debug'
    patroni_watchdog_mode: off  # or 'off', 'required' , 'automatic'
    patroni_watchdog_device: /dev/watchdog
    patroni_postgresql_use_pg_rewind: true  # or 'false'
    # try to use pg_rewind on the former leader when it joins cluster as a replica.
    patroni_remove_data_directory_on_rewind_failure: false  # or 'true' (if use_pg_rewind: 'true')
    # avoid removing the data directory on an unsuccessful rewind
    # if 'true', Patroni will remove the PostgreSQL data directory and recreate the replica.
    patroni_remove_data_directory_on_diverged_timelines: false  # or 'true'
    # if 'true', Patroni will remove the PostgreSQL data directory and recreate the replica
    # if it notices that timelines are diverging and the former master can not start streaming from the new master.
    # https://patroni.readthedocs.io/en/latest/replica_bootstrap.html#bootstrap
    patroni_cluster_bootstrap_method: "initdb"  # or "wal-g", "pgbackrest", "pg_probackup"
    # https://patroni.readthedocs.io/en/latest/replica_bootstrap.html#building-replicas
    patroni_create_replica_methods:
    #  - pgbackrest
    #  - wal_g
    #  - pg_probackup
      - basebackup

    basebackup:
      - { option: "max-rate", value: "100M" }
      - { option: "checkpoint", value: "fast" }

    # CONFIG POSTGRESQL
    postgresql_parameters:
      - { option: "listen_addresses", value: "0.0.0.0" }
      - { option: "port", value: "5432" }
      - { option: "max_connections", value: "10000" }
      - { option: "password_encryption", value: "scram-sha-256" }
      - { option: "unix_socket_directories", value: "/var/run/postgresql" }
      - { option: "shared_buffers", value: "{{ (ansible_facts.memtotal_mb  * 1/ 4) | round | int }}MB" }
      - { option: "work_mem", value: "16MB" } # 32MB : APP ;  64MB : DWH ;  16MB : STAGING
      - { option: "maintenance_work_mem", value: "{% if ansible_facts.memtotal_mb > 31000 %}2GB {% else %}{{ (ansible_facts.memtotal_mb * 1 / 16) | round | int }}MB{% endif %}"}
      - { option: "vacuum_cost_delay", value: "20" }
      - { option: "vacuum_cost_limit", value: "2000" }
      - { option: "effective_io_concurrency", value: "200" }
      - { option: "max_worker_processes", value: "{{ ansible_facts.processor_vcpus }}" }
      - { option: "max_parallel_workers", value: "{{ ansible_facts.processor_vcpus }}" }
      - { option: "max_parallel_workers_per_gather", value: "4" }
      - { option: "max_parallel_maintenance_workers", value: "4" }
      - { option: "wal_level", value: "logical" }
      - { option: "fsync", value: "on" }
      - { option: "synchronous_commit", value: "on" }
      - { option: "full_page_writes", value: "on" }
      - { option: "wal_compression", value: "off" }
      - { option: "wal_log_hints", value: "on" }
      - { option: "wal_buffers", value: "64MB" }
      - { option: "min_wal_size", value: "2GB" }
      - { option: "max_wal_size", value: "12GB" }
      - { option: "checkpoint_completion_target", value: "0.9" }
      - { option: "archive_mode", value: "on" }
      - { option: "archive_command", value: "pgbackrest --stanza={{ pgbackrest_stanza }} archive-push %p" }
      - { option: "max_wal_senders", value: "10" }
      - { option: "random_page_cost", value: "1.1" }
      - { option: "seq_page_cost", value: "1.1" }
      - { option: "effective_cache_size", value: "{{ (ansible_facts.memtotal_mb * 3 / 4) | round | int }}MB" }
      - { option: "enable_bitmapscan", value: "off" }
      - { option: "log_destination", value: "stderr" }
      - { option: "logging_collector", value: "on" }
      - { option: "log_directory", value: "/data/log/pgsql" }
      - { option: "log_filename", value: "postgresql-%H.log" }
      - { option: "log_truncate_on_rotation", value: "on" }
      - { option: "log_rotation_age", value: "60" }
      - { option: "log_rotation_size", value: "0" }
      - { option: "log_min_error_statement", value: "warning" }
      - { option: "log_min_duration_statement", value: "60s" }
      - { option: "log_statement", value: "ddl" }
      - { option: "log_checkpoints", value: "on" }
      - { option: "log_connections", value: "off" }
      - { option: "log_disconnections", value: "off" }
      - { option: "log_error_verbosity", value: "default" }
      - { option: "log_line_prefix", value: "%m [%p]: numberlog=%l user=%u,db=%d,app=%a,client=%h " }
      - { option: "log_lock_waits", value: "on" }
      - { option: "log_temp_files", value: "0" }
      - { option: "log_recovery_conflict_waits", value: "on" }
      - { option: "log_timezone", value: "Asia/Ho_Chi_Minh" }
      - { option: "track_activities", value: "on" }
      - { option: "track_counts", value: "on" }
      - { option: "track_io_timing", value: "on" }
      - { option: "track_functions", value: "all" }
      - { option: "track_commit_timestamp", value: "on" }
      - { option: "autovacuum", value: "on" }
      - { option: "log_autovacuum_min_duration", value: "0" }
      - { option: "autovacuum_vacuum_scale_factor", value: "0.05" }
      - { option: "autovacuum_vacuum_insert_scale_factor", value: "0.05" }
      - { option: "autovacuum_analyze_threshold", value: "1000" }
      - { option: "autovacuum_vacuum_threshold", value: "1000" }
      - { option: "autovacuum_work_mem", value: "2GB" }
      - { option: "autovacuum_vacuum_cost_delay", value: "1ms" }
      - { option: "timezone", value: "Asia/Ho_Chi_Minh" }
      - { option: "lock_timeout", value: "30min" }
      # - { option: "shared_preload_libraries", value: "pg_stat_statements,pg_hint_plan,auto_explain,pgaudit,pg_prewarm" }
      - { option: "shared_preload_libraries", value: "pg_stat_statements,auto_explain,pg_prewarm" }
      - { option: "pg_stat_statements.max", value: "5000" }
      - { option: "pg_stat_statements.track", value: "all" }
      - { option: "cron.database_name", value: "cron.database_name" }
      - { option: "default_toast_compression", value: "lz4"}

    # DEFINE POSTGRESQL VARIABLES PATRONI
    postgresql_exists: false
    postgresql_version: "17"
    postgresql_data_dir: "/data/pgsql/{{ postgresql_version }}"
    postgresql_wal_dir: ""  # if defined, symlink will be created [optional]
    postgresql_conf_dir: "{{ postgresql_data_dir }}"
    postgresql_bin_dir: "/usr/pgsql-{{ postgresql_version }}/bin"
    postgresql_log_dir: "/var/log/postgresql"
    postgresql_unix_socket_dir: "/var/run/postgresql"
    postgresql_home_dir: "/var/lib/pgsql"
    # stats_temp_directory (mount the statistics directory in tmpfs)
    # if postgresql_version < 15
    postgresql_stats_temp_directory_path: "/var/lib/pgsql_stats_tmp"  # or 'none'
    postgresql_stats_temp_directory_size: "1024m"
    postgresql_listen_addr: "0.0.0.0" # Listen on all interfaces. Or use "{{ inventory_hostname }},127.0.0.1" to listen on a specific IP address.
    postgresql_port: "5432"
    postgresql_encoding: "UTF8"  # for bootstrap only (initdb)
    postgresql_locale: "en_US.UTF-8"  # for bootstrap only (initdb)
    postgresql_data_checksums: true  # for bootstrap only (initdb)
    postgresql_password_encryption_algorithm: "scram-sha-256"
    # (optional) list of users to be created (if not already exists)
    postgresql_users:
      - { name: "{{ pgbouncer_auth_username }}", password: "{{ pgbouncer_auth_password }}", flags: "LOGIN", role: "" }
    #  - { name: "monitoring_auth_username", password: "monitoring_user_password", flags: "LOGIN", role: "pg_monitor" } # monitoring Service Account
    #  - { name: "mydb-user", password: "mydb-user-pass", flags: "SUPERUSER" }

    # (optional) list of databases to be created (if not already exists)
    postgresql_databases: []
    #  - { db: "mydatabase", encoding: "UTF8", lc_collate: "ru_RU.UTF-8", lc_ctype: "ru_RU.UTF-8", owner: "mydb-user" }
    #  - { db: "mydatabase2", encoding: "UTF8", lc_collate: "ru_RU.UTF-8", lc_ctype: "ru_RU.UTF-8", owner: "mydb-user", conn_limit: "50" }

    # the password file (~/.pgpass)
    postgresql_pgpass:
      - "localhost:{{ postgresql_port }}:*:{{ patroni_superuser_username }}:{{ patroni_superuser_password }}"
      - "{{ inventory_hostname }}:{{ postgresql_port }}:*:{{ patroni_superuser_username }}:{{ patroni_superuser_password }}"
      - "{{ inventory_hostname }}:{{ postgresql_port }}:*:{{ patroni_replication_username }}:{{ patroni_replication_password }}"
      - "*:{{ pgbouncer_listen_port }}:*:{{ patroni_superuser_username }}:{{ patroni_superuser_password }}"
      - | 
        {% if postgresql_users | length > 0 %}
        {%- for item in postgresql_users %}
        {{ inventory_hostname }}:{{ postgresql_port }}:*:{{ item.name }}:{{ item.password }}
        {% endfor %}
        {% endif %}
    # specify additional hosts that will be added to the pg_hba.conf
    postgresql_pg_hba: 
      - { type: "local", database: "all", user: "{{ patroni_superuser_username }}", address: "", method: "trust" }
      - { type: "local", database: "all", user: "{{ pgbouncer_auth_username }}", address: "", method: "trust" } # required for pgbouncer auth_user
      - { type: "local", database: "replication", user: "{{ patroni_superuser_username }}", address: "", method: "trust" }
      - { type: "local", database: "all", user: "all", address: "", method: "{{ postgresql_password_encryption_algorithm }}" }
      - { type: "host", database: "all", user: "all", address: "127.0.0.1/32", method: "{{ postgresql_password_encryption_algorithm }}" }
      - { type: "host", database: "all", user: "all", address: "::1/128", method: "{{ postgresql_password_encryption_algorithm }}" }
      - { type: "local",database: "replication", user: "all", address: "", method: "peer"}
      - { type: "host", database: "replication", user: "all", address: "127.0.0.1/32", method: "{{ postgresql_password_encryption_algorithm }}" }
      - { type: "host", database: "replication", user: "all", address: "::1/128", method: "{{ postgresql_password_encryption_algorithm }}" }
      - { type: "host", database: "all", user: "all", address: "172.27.11.0/24", method: "{{ postgresql_password_encryption_algorithm }}" }
      - { type: "host", database: "all", user: "all", address: "172.24.177.0/24", method: "{{ postgresql_password_encryption_algorithm }}" }
      - { type: "host", database: "all", user: "all", address: "172.24.178.0/24", method: "{{ postgresql_password_encryption_algorithm }}" }
      - { type: "host", database: "all", user: "all", address: "172.24.181.0/24", method: "{{ postgresql_password_encryption_algorithm }}" }
      - { type: "host", database: "all", user: "all", address: "172.24.186.0/24", method: "{{ postgresql_password_encryption_algorithm }}" }
      - { type: "host", database: "all", user: "all", address: "172.24.187.0/24", method: "{{ postgresql_password_encryption_algorithm }}" }

    postgresql_packages:
      - postgresql{{ postgresql_version }}
      - postgresql{{ postgresql_version }}-server
      - postgresql{{ postgresql_version }}-contrib
    # DEFINE POSTGRESQL OLD STYLE
    # postgres_ver: 17
    # postgres_minor_ver: 2
    # postgres_port: 5432
    # enc_method: md5
    ## Postgres data directory
    # pgdata_dir: "/data/pgsql/{{ postgres_ver }}"
    ## Postgres archive directory pre-definition
    # postgres_archive_dir:
    # postgres_archive_dir: "/data/pgsql/{{ postgres_ver }}/archive_dir"
    ## Postgres archive directory definition
    archive_dir: "{{ postgres_archive_dir }}"
    pgbouncer_ver: 1.24.0
    pgbouncer_install: true  # or 'false' if you do not want to install and configure the pgbouncer service
    pgbouncer_processes: 1  # Number of pgbouncer processes to be used. Multiple processes use the so_reuseport option for better performance.
    pgbouncer_conf_dir: "/data/pgbouncer"
    pgbouncer_log_dir: "/data/log/pgbouncer/pgbouncer.log"
    pgbouncer_listen_addr: "0.0.0.0" # Listen on all interfaces. Or use "{{ inventory_hostname }}" to listen on a specific IP address.
    pgbouncer_listen_port: 6543
    pgbouncer_max_client_conn: 10000
    pgbouncer_max_db_connections: 1000
    pgbouncer_max_prepared_statements: 1024
    pgbouncer_default_pool_size: 100
    pgbouncer_query_wait_timeout: 120
    pgbouncer_default_pool_mode: "transaction"
    pgbouncer_admin_users: "{{ patroni_superuser_username }}"  # comma-separated list of users, who are allowed to change settings
    pgbouncer_stats_users: "{{ patroni_superuser_username }}"  # comma-separated list of users who are just allowed to use SHOW command
    pgbouncer_ignore_startup_parameters: "extra_float_digits,geqo,search_path"
    pgbouncer_auth_type: "hba"
    pgbouncer_auth_user: true # or 'false' if you want to manage the list of users for authentication in the database via userlist.txt
    pgbouncer_auth_username: pgbouncer # user who can query the database via the user_search function
    pgbouncer_auth_password: "pgbouncer-pass" # please change password
    pgbouncer_auth_dbname: "postgres"
    pgbouncer_client_tls_sslmode: "disable"
    pgbouncer_client_tls_key_file: ""
    pgbouncer_client_tls_cert_file: ""
    pgbouncer_client_tls_ca_file: ""
    pgbouncer_client_tls_protocols: "secure" # allowed values: tlsv1.0, tlsv1.1, tlsv1.2, tlsv1.3, all, secure (tlsv1.2,tlsv1.3)
    pgbouncer_client_tls_ciphers: "default" # allowed values: default, secure, fast, normal, all (not recommended)

    haproxy_listen_port:
      master: 5000
      replicas: 5001
      replicas_sync: 5002
      replicas_async: 5003
    # The following ('_direct') ports are used for direct connections to the PostgreSQL database,
    # bypassing the PgBouncer connection pool (if 'pgbouncer_install' is 'true').
    # Uncomment the relevant lines if you need to set up direct connections.
    #  master_direct: 6000
    #  replicas_direct: 6001
    #  replicas_sync_direct: 6002
    #  replicas_async_direct: 6003
      stats: 7000
    haproxy_maxconn:
      global: 100000
      master: 10000
      replica: 10000
    haproxy_timeout:
      client: "60m"
      server: "60m"

    # Cluster variables
    cluster_vip: "172.24.177.85"  # IP address for client access to the databases in the cluster (optional).
    vip_interface: "{{ ansible_default_ipv4.interface }}"  # interface name (e.g., "ens32").
    # pgBackRest
    pgbackrest_install: true  # or 'true'
    pgbackrest_install_from_pgdg_repo: true  # or 'false'
    pgbackrest_version: "2.53.1"
    pgbackrest_stanza: "{{ patroni_cluster_name }}"  # specify your --stanza
    pgbackrest_repo_type: "posix"  # or "s3", "gcs", "azure"
    pgbackrest_repo_host: ""  # dedicated repository host (optional)
    pgbackrest_repo_user: "postgres"
    pgbackrest_conf_file: "/etc/pgbackrest/pgbackrest.conf"
    # config https://pgbackrest.org/configuration.html
    pgbackrest_conf:
      global:  # [global] section
        - { option: "log-level-file", value: "detail" }
        - { option: "log-path", value: "/var/log/pgbackrest" }
        # - { option: "repo1-host", value: "{{ pgbackrest_repo_host }}" }
        # - { option: "repo1-host-user", value: "{{ pgbackrest_repo_user }}" }
        - { option: "repo1-type", value: "{{ pgbackrest_repo_type | lower }}" }
        - { option: "repo1-path", value: "/var/lib/pgbackrest" }
        - { option: "repo1-retention-full", value: "4" }
        - { option: "repo1-host-config", value: "{{ pgbackrest_conf_file }}" }
        # - { option: "repo1-host-config-include-path", value: "/etc/pgbackrest/conf.d/" }
        # - { option: "repo1-retention-archive", value: "4" }
        - { option: "start-fast", value: "y" }
        - { option: "stop-auto", value: "y" }
        - { option: "resume", value: "y" }
        - { option: "link-all", value: "y" }
        - { option: "spool-path", value: "/var/spool/pgbackrest" }
        - { option: "archive-async", value: "y" } # Enables asynchronous WAL archiving (details: https://pgbackrest.org/user-guide.html#async-archiving)
        - { option: "archive-get-queue-max", value: "1GiB" }
    #    - { option: "archive-push-queue-max", value: "100GiB" }
        # - { option: "backup-standby", value: "y" } # When set to 'y', standby servers will be automatically added to the stanza section.
        - { option: "compress-level", value: "1" }
    #    - { option: "", value: "" }
      stanza:  # [stanza_name] section
        - { option: "process-max", value: "{{ (ansible_processor_vcpus/2) |round(0,'ceil') | int }}" }
        - { option: "log-level-console", value: "info" }
        - { option: "recovery-option", value: "recovery_target_action=promote" }
        - { option: "pg1-socket-path", value: "{{ postgresql_unix_socket_dir }}" }
        - { option: "pg1-path", value: "{{ postgresql_data_dir }}" }
        - { option: "pg1-host-config", value: "{{ pgbackrest_conf_file }}" }
        - { option: "pg1-host-config-include-path", value: "/etc/pgbackrest/conf.d/" }
    #    - { option: "", value: "" }
    pgbackrest_archive_command: "pgbackrest --stanza={{ pgbackrest_stanza }} archive-push %p"
    # (optional) dedicated backup server config (if "repo_host" is set)
    pgbackrest_server_conf:
      global:
        - { option: "log-level-file", value: "detail" }
        - { option: "log-level-console", value: "info" }
        - { option: "log-path", value: "/var/log/pgbackrest" }
        - { option: "repo1-type", value: "{{ pgbackrest_repo_type | lower }}" }
        - { option: "repo1-path", value: "/var/lib/pgbackrest" }
        - { option: "repo1-retention-full", value: "4" }
        - { option: "repo1-host-config", value: "{{ pgbackrest_conf_file }}" }
        # - { option: "repo1-host-config-include-path", value: "/etc/pgbackrest/conf.d/" }
        # - { option: "repo1-retention-archive", value: "4" }
        - { option: "repo1-bundle", value: "y" }
        - { option: "repo1-block", value: "y" }
        - { option: "start-fast", value: "y" }
        - { option: "stop-auto", value: "y" }
        - { option: "resume", value: "y" }
        - { option: "link-all", value: "y" }
        - { option: "archive-check", value: "y" }
        - { option: "archive-copy", value: "n" }
        - { option: "backup-standby", value: "y" }
    #    - { option: "", value: "" }
    # the stanza section will be generated automatically
    # By default, the cron jobs is created on the database server.
    # If 'repo_host' is defined, the cron jobs will be created on the pgbackrest server.
    pgbackrest_cron_jobs:
      - name: "pgBackRest: Full Backup"
        file: "/etc/cron.d/pgbackrest-{{ patroni_cluster_name }}"
        user: "postgres"
        minute: "30"
        hour: "6"
        day: "*"
        month: "*"
        weekday: "*"
        job: "pgbackrest --stanza={{ pgbackrest_stanza }} --type=full backup"
        # job: "if [ $(psql -tAXc 'select pg_is_in_recovery()') = 'f' ]; then pgbackrest --type=full --stanza={{ pgbackrest_stanza }} backup; fi"
      # - name: "pgBackRest: Incr Backup"
      #   file: "/etc/cron.d/pgbackrest-{{ patroni_cluster_name }}"
      #   user: "postgres"
      #   minute: "30"
      #   hour: "6"
      #   day: "*"
      #   month: "*"
      #   weekday: "1-6"
      #   job: "pgbackrest --stanza={{ pgbackrest_stanza }} --type=incr backup"
      #   # job: "if [ $(psql -tAXc 'select pg_is_in_recovery()') = 'f' ]; then pgbackrest --type=diff --stanza={{ pgbackrest_stanza }} backup; fi"

    script_backup: |
      #!/usr/bin/env bash

      # mkdir -p /backup/backup-postgres
      # chown postgres:postgres /backup/backup-postgres/
      # mkdir -p /backup/backup-postgres/scripts
      # chown postgres:postgres /backup/backup-postgres/scripts
      # cronjob file: /etc/cron.d/backup_all_db_pg
      # 00 00 * * * postgres /backup/backup-postgres/scripts/backup_all_db.sh

      BACKUP_NAME="{{ inventory_hostname }}"
      KEEP_DAYS=7
      PGHOST=${PGHOST:-localhost}
      PGPORT=${PGPORT:-5432}
      PGUSER="postgres"
      FOLDER_BACKUP="/backup/backup-postgres/"
      FILENAME_DDL="backup_ddl_${BACKUP_NAME}_$(date +"%F-%Hh").sql"
      FILENAME_DATA="backup_data_${BACKUP_NAME}_$(date +"%F-%Hh").sql"
      OPTION_DUMP="--exclude-database=template0  --exclude-database=template1 --disable-triggers"

      # SERVER RSYNC DAEMON
      RSYNC_SERVER=172.24.178.42
      MODULE=POSTGRES
      RSYNC_FOLDER_NAME="backup-${BACKUP_NAME}"

      # run backup if pg_dumpall exist
      if [ "$(command -v pg_dumpall)" ]; then
            # command backup ddl all db exclude template0, template1
            pg_dumpall -d "postgres://${PGUSER}@${PGHOST}:${PGPORT}" ${OPTION_DUMP} -s -f ${FOLDER_BACKUP}/${FILENAME_DDL}
            if [ $? -eq 0 ]; then
                  logger -t backup_postgres "backup only schema successful."
            else
                  logger -t backup_postgres "backup only schema failed."
            fi
            # command backup full data all db exclude template0, template1
            pg_dumpall -d "postgres://${PGUSER}@${PGHOST}:${PGPORT}" ${OPTION_DUMP} -f ${FOLDER_BACKUP}/${FILENAME_DATA}
            if [ $? -eq 0 ]; then
                  logger -t backup_postgres "backup full data successful."
            else
                  logger -t backup_postgres "backup full data failed."
            fi
      fi

      # rsync folder backup
      rsync -n -a -z --progress ${FOLDER_BACKUP}/${FILENAME_DDL}  "${RSYNC_SERVER}"::"${MODULE}"/"${RSYNC_FOLDER_NAME}"/
      if [ $? -eq 0 ]; then
          logger -t backup_postgres "rsync file backup ddl to ${RSYNC_SERVER} successful."
      else
          logger -t backup_postgres "sync file backup ddl to ${RSYNC_SERVER} failed."
      fi

      rsync -n -a -z --progress ${FOLDER_BACKUP}/${FILENAME_DATA}  "${RSYNC_SERVER}"::"${MODULE}"/"${RSYNC_FOLDER_NAME}"/
      if [ $? -eq 0 ]; then
          logger -t backup_postgres "rsync file backup full data to ${RSYNC_SERVER} successful."
      else
          logger -t backup_postgres "sync file backup full data to ${RSYNC_SERVER} failed."
      fi

      # run delete old backup
      find ${FOLDER_BACKUP}/ -name "backup_*.sql" -mtime +${KEEP_DAYS} -type f -print -delete
